{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7d855b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b314092",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbbfd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(784, 540)\n",
    "        self.layer2 = nn.Linear(540, 360)\n",
    "        self.layer3 = nn.Linear(360, 240)\n",
    "        self.layer4 = nn.Linear(240, 120)\n",
    "        self.layer5 = nn.Linear(120, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = F.relu(self.layer4(x))\n",
    "        return self.layer5(x) #Activation not required, \n",
    "                          #since Cross Entropy does that by itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc581f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7934c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target =  Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f6f4d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.0f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21b86406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.306501\n",
      "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.298641\n",
      "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.306758\n",
      "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.300812\n",
      "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.300426\n",
      "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.305161\n",
      "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.300425\n",
      "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.297726\n",
      "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.299365\n",
      "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.301428\n",
      "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.299897\n",
      "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.309114\n",
      "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.299283\n",
      "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.295502\n",
      "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.301176\n",
      "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.295355\n",
      "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.294708\n",
      "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.298003\n",
      "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.299109\n",
      "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.293289\n",
      "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.302163\n",
      "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.290952\n",
      "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.289928\n",
      "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.289923\n",
      "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.297372\n",
      "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.290200\n",
      "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.303524\n",
      "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.286390\n",
      "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.293789\n",
      "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.290051\n",
      "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.292569\n",
      "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.287962\n",
      "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.292510\n",
      "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.297355\n",
      "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.292480\n",
      "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.285728\n",
      "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.282770\n",
      "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.281774\n",
      "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.290788\n",
      "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.286459\n",
      "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.285421\n",
      "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.281304\n",
      "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.281821\n",
      "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.286628\n",
      "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.287995\n",
      "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.285746\n",
      "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.276224\n",
      "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.283053\n",
      "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.283083\n",
      "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.275148\n",
      "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.264800\n",
      "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.266568\n",
      "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.278583\n",
      "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.262504\n",
      "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.272218\n",
      "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.260249\n",
      "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.264521\n",
      "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.263381\n",
      "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.265723\n",
      "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.265658\n",
      "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.259741\n",
      "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.248134\n",
      "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.255664\n",
      "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.230863\n",
      "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.240742\n",
      "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.258511\n",
      "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.241114\n",
      "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.233324\n",
      "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.206600\n",
      "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.221414\n",
      "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.202160\n",
      "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.222151\n",
      "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.189007\n",
      "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.191080\n",
      "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.149599\n",
      "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.169423\n",
      "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.161968\n",
      "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.098497\n",
      "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.139038\n",
      "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.096698\n",
      "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.076509\n",
      "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.038600\n",
      "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 1.965353\n",
      "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.068976\n",
      "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 1.979707\n",
      "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 1.828358\n",
      "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 1.953939\n",
      "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 1.823474\n",
      "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 1.796668\n",
      "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 1.727202\n",
      "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 1.603034\n",
      "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.639460\n",
      "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 1.489335\n",
      "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 1.490499\n",
      "Training time: 0m 14s\n",
      "===========================\n",
      "Test set: Average loss: 0.0227, Accuracy: 5968/10000 (60%)\n",
      "Testing time: 0m 16s\n",
      "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 1.409060\n",
      "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.328163\n",
      "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.436089\n",
      "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.349051\n",
      "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.426052\n",
      "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.169258\n",
      "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.091054\n",
      "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.057080\n",
      "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.059247\n",
      "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 0.838304\n",
      "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.009013\n",
      "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 0.956057\n",
      "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.030923\n",
      "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.038421\n",
      "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 0.686972\n",
      "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 0.758730\n",
      "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 0.954877\n",
      "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 0.767959\n",
      "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 0.964685\n",
      "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 0.848192\n",
      "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 0.801790\n",
      "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 0.680879\n",
      "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 0.563627\n",
      "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.708368\n",
      "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 0.670820\n",
      "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.666268\n",
      "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.795330\n",
      "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 0.813573\n",
      "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.754903\n",
      "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 0.549993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.653829\n",
      "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.832338\n",
      "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.686780\n",
      "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.818538\n",
      "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.708237\n",
      "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.725737\n",
      "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.618167\n",
      "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.641758\n",
      "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.560619\n",
      "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.377257\n",
      "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.645476\n",
      "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.908931\n",
      "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.580500\n",
      "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.426528\n",
      "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.826086\n",
      "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.635461\n",
      "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.633064\n",
      "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.698438\n",
      "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.607295\n",
      "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.453770\n",
      "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.432787\n",
      "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.481354\n",
      "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.754717\n",
      "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.487082\n",
      "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.414695\n",
      "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.467121\n",
      "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.431025\n",
      "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.657587\n",
      "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.763368\n",
      "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.655126\n",
      "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.372939\n",
      "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.612238\n",
      "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.496573\n",
      "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.544288\n",
      "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.734680\n",
      "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.415162\n",
      "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.412684\n",
      "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.425319\n",
      "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.515175\n",
      "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.390296\n",
      "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.335896\n",
      "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.704270\n",
      "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.486471\n",
      "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.436269\n",
      "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.335300\n",
      "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.525786\n",
      "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.594317\n",
      "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.553512\n",
      "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.481294\n",
      "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.352257\n",
      "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.478952\n",
      "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.516105\n",
      "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.393566\n",
      "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.569883\n",
      "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.216381\n",
      "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.472553\n",
      "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.607635\n",
      "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.372341\n",
      "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.494433\n",
      "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.271659\n",
      "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.538245\n",
      "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.566235\n",
      "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.312972\n",
      "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.296546\n",
      "Training time: 0m 12s\n",
      "===========================\n",
      "Test set: Average loss: 0.0070, Accuracy: 8689/10000 (87%)\n",
      "Testing time: 0m 13s\n",
      "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.547488\n",
      "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.482885\n",
      "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.639544\n",
      "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.285049\n",
      "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.445467\n",
      "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.371994\n",
      "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.518098\n",
      "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.304809\n",
      "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.446675\n",
      "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.416381\n",
      "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.285887\n",
      "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.577712\n",
      "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.475551\n",
      "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.254619\n",
      "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.273262\n",
      "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.510123\n",
      "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.447542\n",
      "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.384639\n",
      "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.623455\n",
      "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.355280\n",
      "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.227977\n",
      "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.341916\n",
      "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.486866\n",
      "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.584085\n",
      "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.391720\n",
      "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.587992\n",
      "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.307393\n",
      "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.447024\n",
      "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.571824\n",
      "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.499064\n",
      "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.191254\n",
      "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.394234\n",
      "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.382254\n",
      "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.409457\n",
      "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.409130\n",
      "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.247270\n",
      "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.395707\n",
      "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.599856\n",
      "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.373749\n",
      "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.345866\n",
      "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.383260\n",
      "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.495931\n",
      "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.358636\n",
      "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.531486\n",
      "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.387767\n",
      "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.355213\n",
      "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.447356\n",
      "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.568899\n",
      "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.385448\n",
      "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.504124\n",
      "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.440392\n",
      "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.400569\n",
      "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.345192\n",
      "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.327319\n",
      "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.299570\n",
      "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.707961\n",
      "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.319794\n",
      "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.235178\n",
      "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.243238\n",
      "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.377339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.192533\n",
      "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.370910\n",
      "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.394141\n",
      "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.423335\n",
      "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.274614\n",
      "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.568313\n",
      "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.336280\n",
      "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.469015\n",
      "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.341923\n",
      "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.307017\n",
      "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.511630\n",
      "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.559431\n",
      "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.299907\n",
      "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.306634\n",
      "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.318970\n",
      "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.258875\n",
      "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.182322\n",
      "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.260002\n",
      "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.734060\n",
      "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.207485\n",
      "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.304295\n",
      "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.270591\n",
      "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.604868\n",
      "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.302032\n",
      "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.416130\n",
      "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.525036\n",
      "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.536435\n",
      "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.339860\n",
      "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.399385\n",
      "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.259347\n",
      "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.383844\n",
      "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.332528\n",
      "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.278711\n",
      "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.411783\n",
      "Training time: 0m 12s\n",
      "===========================\n",
      "Test set: Average loss: 0.0048, Accuracy: 9097/10000 (91%)\n",
      "Testing time: 0m 14s\n",
      "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.181447\n",
      "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.218530\n",
      "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.382372\n",
      "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.225648\n",
      "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.161845\n",
      "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.388311\n",
      "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.206944\n",
      "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.400702\n",
      "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.284756\n",
      "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.323843\n",
      "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.432308\n",
      "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.314276\n",
      "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.355370\n",
      "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.233250\n",
      "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.280399\n",
      "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.252321\n",
      "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.301999\n",
      "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.241353\n",
      "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.255089\n",
      "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.496810\n",
      "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.265862\n",
      "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.261255\n",
      "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.351393\n",
      "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.333408\n",
      "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.357164\n",
      "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.147011\n",
      "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.307763\n",
      "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.278556\n",
      "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.138116\n",
      "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.286967\n",
      "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.136260\n",
      "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.203008\n",
      "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.220641\n",
      "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.316170\n",
      "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.228724\n",
      "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.289116\n",
      "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.499689\n",
      "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.299985\n",
      "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.299519\n",
      "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.222258\n",
      "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.185179\n",
      "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.273427\n",
      "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.164052\n",
      "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.348505\n",
      "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.211764\n",
      "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.154441\n",
      "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.284622\n",
      "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.249224\n",
      "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.263865\n",
      "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.140250\n",
      "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.197300\n",
      "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.361205\n",
      "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.193679\n",
      "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.357995\n",
      "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.298057\n",
      "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.190277\n",
      "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.253487\n",
      "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.178185\n",
      "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.122196\n",
      "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.237832\n",
      "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.166210\n",
      "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.455211\n",
      "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.213756\n",
      "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.191841\n",
      "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.354092\n",
      "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.197766\n",
      "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.220401\n",
      "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.319931\n",
      "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.109482\n",
      "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.195414\n",
      "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.203647\n",
      "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.294214\n",
      "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.329780\n",
      "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.186644\n",
      "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.131454\n",
      "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.153410\n",
      "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.080036\n",
      "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.200618\n",
      "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.158455\n",
      "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.166727\n",
      "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.272752\n",
      "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.188072\n",
      "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.171465\n",
      "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.381034\n",
      "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.113494\n",
      "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.173142\n",
      "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.095791\n",
      "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.124143\n",
      "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.225714\n",
      "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.277702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.100237\n",
      "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.229624\n",
      "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.308286\n",
      "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.467667\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0034, Accuracy: 9366/10000 (94%)\n",
      "Testing time: 0m 14s\n",
      "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.232569\n",
      "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.325242\n",
      "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.276543\n",
      "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.155829\n",
      "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.225156\n",
      "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.296618\n",
      "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.186217\n",
      "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.117459\n",
      "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.327358\n",
      "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.180557\n",
      "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.635485\n",
      "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.320792\n",
      "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.266493\n",
      "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.199125\n",
      "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.221186\n",
      "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.236094\n",
      "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.139407\n",
      "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.106930\n",
      "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.336221\n",
      "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.136652\n",
      "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.106341\n",
      "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.158573\n",
      "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.113783\n",
      "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.092263\n",
      "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.109434\n",
      "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.135905\n",
      "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.222426\n",
      "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.287880\n",
      "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.110531\n",
      "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.049714\n",
      "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.161401\n",
      "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.304721\n",
      "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.182459\n",
      "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.175339\n",
      "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.109652\n",
      "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.099514\n",
      "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.155879\n",
      "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.179412\n",
      "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.211188\n",
      "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.070148\n",
      "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.231784\n",
      "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.281330\n",
      "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.221314\n",
      "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.532435\n",
      "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.272471\n",
      "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.097967\n",
      "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.186125\n",
      "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.231574\n",
      "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.106584\n",
      "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.051602\n",
      "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.198389\n",
      "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.186419\n",
      "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.062277\n",
      "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.169834\n",
      "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.107698\n",
      "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.232365\n",
      "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.187043\n",
      "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.158550\n",
      "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.114108\n",
      "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.125107\n",
      "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.143025\n",
      "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.116665\n",
      "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.173860\n",
      "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.138626\n",
      "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.141983\n",
      "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.308865\n",
      "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.176552\n",
      "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.142115\n",
      "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.201904\n",
      "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.133304\n",
      "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.112886\n",
      "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.200205\n",
      "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.250739\n",
      "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.094101\n",
      "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.131919\n",
      "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.260920\n",
      "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.465542\n",
      "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.261837\n",
      "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.148360\n",
      "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.097748\n",
      "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.182930\n",
      "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.195622\n",
      "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.092901\n",
      "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.176631\n",
      "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.223066\n",
      "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.318828\n",
      "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.180581\n",
      "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.037191\n",
      "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.089936\n",
      "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.332045\n",
      "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.194806\n",
      "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.162373\n",
      "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.129132\n",
      "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.168560\n",
      "Training time: 0m 12s\n",
      "===========================\n",
      "Test set: Average loss: 0.0026, Accuracy: 9496/10000 (95%)\n",
      "Testing time: 0m 14s\n",
      "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.145638\n",
      "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.061230\n",
      "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.106007\n",
      "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.250412\n",
      "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.196168\n",
      "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.115610\n",
      "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.077797\n",
      "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.263250\n",
      "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.165376\n",
      "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.075566\n",
      "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.093164\n",
      "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.160022\n",
      "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.091806\n",
      "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.312384\n",
      "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.092720\n",
      "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.079007\n",
      "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.183890\n",
      "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.077056\n",
      "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.107649\n",
      "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.210018\n",
      "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.125670\n",
      "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.138661\n",
      "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.148196\n",
      "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.167591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.107483\n",
      "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.066882\n",
      "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.052323\n",
      "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.131950\n",
      "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.142268\n",
      "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.224076\n",
      "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.046054\n",
      "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.070304\n",
      "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.334669\n",
      "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.167952\n",
      "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.083913\n",
      "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.050933\n",
      "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.156219\n",
      "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.100668\n",
      "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.108962\n",
      "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.113462\n",
      "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.216546\n",
      "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.199563\n",
      "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.380658\n",
      "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.090199\n",
      "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.144321\n",
      "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.169523\n",
      "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.185581\n",
      "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.083884\n",
      "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.197254\n",
      "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.088237\n",
      "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.290564\n",
      "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.037653\n",
      "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.230476\n",
      "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.271816\n",
      "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.140588\n",
      "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.097137\n",
      "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.464654\n",
      "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.087854\n",
      "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.327848\n",
      "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.095307\n",
      "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.055510\n",
      "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.188881\n",
      "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.079466\n",
      "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.075354\n",
      "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.138554\n",
      "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.145897\n",
      "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.106553\n",
      "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.066762\n",
      "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.047915\n",
      "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.097610\n",
      "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.163221\n",
      "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.103161\n",
      "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.143757\n",
      "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.231575\n",
      "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.053159\n",
      "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.214240\n",
      "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.078671\n",
      "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.209593\n",
      "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.332024\n",
      "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.201071\n",
      "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.051710\n",
      "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.048523\n",
      "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.409395\n",
      "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.422437\n",
      "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.081233\n",
      "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.082614\n",
      "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.064897\n",
      "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.133731\n",
      "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.106107\n",
      "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.185341\n",
      "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.167658\n",
      "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.212746\n",
      "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.121826\n",
      "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.134964\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0022, Accuracy: 9558/10000 (96%)\n",
      "Testing time: 0m 14s\n",
      "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.087309\n",
      "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.128077\n",
      "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.026578\n",
      "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.085315\n",
      "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.044548\n",
      "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.066544\n",
      "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.117317\n",
      "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.133191\n",
      "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.318185\n",
      "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.112825\n",
      "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.141187\n",
      "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.174413\n",
      "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.099053\n",
      "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.073617\n",
      "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.075627\n",
      "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.168659\n",
      "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.085068\n",
      "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.076349\n",
      "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.066793\n",
      "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.103839\n",
      "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.328749\n",
      "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.066116\n",
      "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.211757\n",
      "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.081417\n",
      "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.077224\n",
      "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.113564\n",
      "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.152631\n",
      "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.128817\n",
      "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.190289\n",
      "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.213919\n",
      "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.064061\n",
      "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.161114\n",
      "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.124855\n",
      "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.119982\n",
      "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.084085\n",
      "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.069349\n",
      "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.114698\n",
      "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.087171\n",
      "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.141720\n",
      "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.191135\n",
      "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.231846\n",
      "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.147982\n",
      "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.130816\n",
      "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.073632\n",
      "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.350446\n",
      "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.067243\n",
      "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.279843\n",
      "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.081992\n",
      "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.178368\n",
      "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.194410\n",
      "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.082101\n",
      "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.023591\n",
      "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.130540\n",
      "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.124188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.168885\n",
      "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.072326\n",
      "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.070794\n",
      "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.111353\n",
      "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.034462\n",
      "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.058302\n",
      "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.158532\n",
      "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.201367\n",
      "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.081598\n",
      "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.164575\n",
      "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.066989\n",
      "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.186331\n",
      "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.180059\n",
      "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.292497\n",
      "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.322115\n",
      "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.147210\n",
      "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.108022\n",
      "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.077166\n",
      "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.190083\n",
      "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.095865\n",
      "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.061337\n",
      "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.051182\n",
      "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.124909\n",
      "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.203064\n",
      "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.115695\n",
      "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.222611\n",
      "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.028031\n",
      "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.094582\n",
      "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.170293\n",
      "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.099647\n",
      "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.061709\n",
      "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.130770\n",
      "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.124931\n",
      "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.130695\n",
      "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.114560\n",
      "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.064397\n",
      "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.147843\n",
      "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.099566\n",
      "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.126645\n",
      "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.135292\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0019, Accuracy: 9638/10000 (96%)\n",
      "Testing time: 0m 14s\n",
      "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.129563\n",
      "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.170876\n",
      "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.130587\n",
      "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.154034\n",
      "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.311554\n",
      "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.073129\n",
      "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.054129\n",
      "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.107768\n",
      "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.106609\n",
      "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.049350\n",
      "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.133443\n",
      "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.043902\n",
      "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.143715\n",
      "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.050254\n",
      "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.056934\n",
      "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.044818\n",
      "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.074701\n",
      "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.139270\n",
      "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.083758\n",
      "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.188627\n",
      "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.026811\n",
      "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.032989\n",
      "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.065824\n",
      "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.059314\n",
      "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.287282\n",
      "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.110414\n",
      "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.086923\n",
      "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.022409\n",
      "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.153180\n",
      "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.172455\n",
      "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.241772\n",
      "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.365189\n",
      "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.125323\n",
      "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.167436\n",
      "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.078715\n",
      "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.106206\n",
      "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.100218\n",
      "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.379394\n",
      "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.022952\n",
      "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.090531\n",
      "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.022800\n",
      "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.048559\n",
      "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.075948\n",
      "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.035091\n",
      "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.091203\n",
      "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.056664\n",
      "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.103096\n",
      "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.109242\n",
      "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.109388\n",
      "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.064213\n",
      "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.187405\n",
      "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.043314\n",
      "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.115493\n",
      "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.039997\n",
      "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.088998\n",
      "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.066288\n",
      "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.040424\n",
      "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.091610\n",
      "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.061236\n",
      "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.027856\n",
      "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.124274\n",
      "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.016515\n",
      "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.096720\n",
      "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.135959\n",
      "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.050476\n",
      "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.063200\n",
      "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.072496\n",
      "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.034893\n",
      "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.028063\n",
      "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.148952\n",
      "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.058986\n",
      "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.329874\n",
      "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.063676\n",
      "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.078026\n",
      "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.145241\n",
      "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.068048\n",
      "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.032986\n",
      "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.221440\n",
      "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.082817\n",
      "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.019515\n",
      "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.014096\n",
      "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.080292\n",
      "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.040242\n",
      "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.247148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.070171\n",
      "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.059061\n",
      "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.084114\n",
      "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.071544\n",
      "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.071491\n",
      "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.214013\n",
      "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.091940\n",
      "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.039618\n",
      "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.150169\n",
      "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.021373\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9688/10000 (97%)\n",
      "Testing time: 0m 15s\n",
      "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.073896\n",
      "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.060934\n",
      "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.040837\n",
      "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.032538\n",
      "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.088674\n",
      "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.127770\n",
      "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.048039\n",
      "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.115735\n",
      "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.129695\n",
      "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.085017\n",
      "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.087128\n",
      "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.154885\n",
      "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.113518\n",
      "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.119246\n",
      "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.029412\n",
      "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.141803\n",
      "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.128332\n",
      "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.026756\n",
      "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.084380\n",
      "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.052717\n",
      "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.073936\n",
      "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.099535\n",
      "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.088008\n",
      "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.100620\n",
      "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.029293\n",
      "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.079361\n",
      "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.095111\n",
      "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.029309\n",
      "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.074460\n",
      "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.100327\n",
      "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.067594\n",
      "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.023606\n",
      "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.019301\n",
      "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.091287\n",
      "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.077266\n",
      "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.025012\n",
      "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.110588\n",
      "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.023110\n",
      "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.067866\n",
      "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.048499\n",
      "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.039684\n",
      "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.123305\n",
      "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.108417\n",
      "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.113555\n",
      "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.089757\n",
      "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.126126\n",
      "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.211305\n",
      "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.080875\n",
      "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.091077\n",
      "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.080639\n",
      "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.116648\n",
      "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.057676\n",
      "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.154201\n",
      "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.074847\n",
      "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.019214\n",
      "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.078583\n",
      "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.108560\n",
      "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.037833\n",
      "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.043041\n",
      "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.078373\n",
      "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.029245\n",
      "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.056076\n",
      "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.125332\n",
      "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.087219\n",
      "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.152786\n",
      "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.034838\n",
      "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.085881\n",
      "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.070190\n",
      "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.126506\n",
      "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.034150\n",
      "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.038031\n",
      "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.034928\n",
      "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.082853\n",
      "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.128742\n",
      "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.026051\n",
      "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.131267\n",
      "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.161985\n",
      "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.094449\n",
      "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.113501\n",
      "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.094865\n",
      "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.182741\n",
      "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.028962\n",
      "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.115939\n",
      "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.017549\n",
      "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.057706\n",
      "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.119965\n",
      "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.032903\n",
      "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.093877\n",
      "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.038117\n",
      "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.054429\n",
      "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.036619\n",
      "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.088329\n",
      "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.028708\n",
      "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.188372\n",
      "Training time: 0m 13s\n",
      "===========================\n",
      "Test set: Average loss: 0.0017, Accuracy: 9669/10000 (97%)\n",
      "Testing time: 0m 15s\n",
      "Total Time: 2m 8s\n",
      "Model was trained!\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "for epoch in range(1, 10):\n",
    "    epoch_start = time.time()\n",
    "    train(epoch)\n",
    "    m, s = divmod(time.time() - epoch_start, 60)\n",
    "    print(f'Training time: {m:.0f}m {s:.0f}s')\n",
    "    test()\n",
    "    m, s = divmod(time.time() - epoch_start, 60)\n",
    "    print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
    "\n",
    "m, s = divmod(time.time() - since, 60)\n",
    "print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00862d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
